{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple recommender example using Python\n",
    "\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/\n",
    "\n",
    "A very friendly explanation on Youtube:\n",
    "https://www.youtube.com/watch?v=ZspR5PZemcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data\n",
    "\n",
    "The quantity and quality of the data determines the quality of predictions. \n",
    "Gather enough data, refine (extract) relevant subset,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Content-based filtering\n",
    "\n",
    "Assume that if a user like A, and B is similar to A, then the user will probably like B, too.\n",
    "Consider a *profile vector*, which contains behavior of a Netflix user. This vector can be compared to *item vectors* of videos containing informations such as genre, cast, directors, etc. \n",
    "\n",
    "\n",
    "#### Measures\n",
    "The similarity can be calculated as the cosine between vectors as\n",
    "#### Cosine similarity\n",
    "\n",
    "\\begin{equation*}\n",
    " sim(A,B) = cos(\\theta) = \\frac{A \\dot B}{\\left \\| A \\right \\|\\left \\| B \\right \\|}\n",
    "\\end{equation*}\n",
    "\n",
    "#### Euclidean distance\n",
    "\n",
    "#### Pearson's Correlation\n",
    "\n",
    "\\begin{equation*}\n",
    "sim(u,v)=\\frac { \\sum { ({ r }_{ ui }-{ \\bar { r }  }_{ u })({ r }_{ vi }-\\bar { { r }_{ v } } ) }  }{ \\sqrt { { \\sum { ({ r }_{ ui }-{ \\bar { r }  }_{ u }) }  }^{ 2 } } \\sqrt { { \\sum { ({ r }_{ vi }-\\bar { { r }_{ v } } ) }  }^{ 2 } }  } \n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "#### Draw back\n",
    "This method can only be applied to the data set of the *same* kind as the user has rated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 More general, collaborative filtering\n",
    "\n",
    "#### Between users\n",
    "If user A and B both like a,b, and B also like c, then A may like c, too. \n",
    "\n",
    "$P_{u,i}$, the prediction of an item i for a user u can be calculated as\n",
    "\n",
    "\\begin{equation*}\n",
    "{ P }_{ u,i }=\\frac { \\sum _{ v }^{  }{ \\left( { r }_{ v,i }*{ s }_{ u,v } \\right)  }  }{ \\sum _{ v }^{  }{ { s }_{ u,v } }  } \n",
    "\\end{equation*}\n",
    "\n",
    ", where v denotes other user, and S represents the similarity between users.\n",
    "\n",
    "Calculating similiarty between all pairs of users is time consuming. Thus a subset of users might be used in practice.\n",
    "\n",
    "The same can be done **between items.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90570, 4) (9430, 4)\n"
     ]
    }
   ],
   "source": [
    "u_cols = [\"user_id\", \"age\", \"sex\", 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=u_cols, encoding=\"latin-1\")\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=r_cols, encoding=\"latin-1\")\n",
    "ratings_train = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "\n",
    "i_cols = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "          \"unknown\", 'Action', 'Adventure', 'Animation', 'Children\\'s',\n",
    "          'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "          'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance',\n",
    "          'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "items = pd.read_csv('ml-100k/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
    "\n",
    "print(ratings_train.shape, ratings_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering model\n",
    " both user similarity and item similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = ratings.user_id.unique().shape[0]\n",
    "n_items = ratings.movie_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 because pandas index starts from 1.\n",
    "\n",
    "data_matrix = np.zeros((n_users, n_items))\n",
    "for line in ratings.itertuples():\n",
    "    data_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\"\"\"\n",
    "    Distance metrics ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan']\n",
    "\"\"\"\n",
    "\n",
    "# user-user similarity, item-item similarity\n",
    "user_similarity = pairwise_distances(data_matrix, metric=\"cosine\")\n",
    "item_similarity = pairwise_distances(data_matrix.T, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type=\"user\"):\n",
    "    \"Predicted rating based on \"\n",
    "    if type=='user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + \\\n",
    "                similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = predict(data_matrix, user_similarity, type=\"user\")\n",
    "i_pred = predict(data_matrix, item_similarity, type=\"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = turicreate.SFrame(ratings_train)\n",
    "test_data = turicreate.SFrame(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Warning: Ignoring columns unix_timestamp;</pre>"
      ],
      "text/plain": [
       "Warning: Ignoring columns unix_timestamp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    To use these columns in scoring predictions, use a model that allows the use of additional features.</pre>"
      ],
      "text/plain": [
       "    To use these columns in scoring predictions, use a model that allows the use of additional features."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Preparing data set.</pre>"
      ],
      "text/plain": [
       "Preparing data set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data has 90570 observations with 943 users and 1680 items.</pre>"
      ],
      "text/plain": [
       "    Data has 90570 observations with 943 users and 1680 items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data prepared in: 0.041771s</pre>"
      ],
      "text/plain": [
       "    Data prepared in: 0.041771s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>90570 observations to process; with 1680 unique items.</pre>"
      ],
      "text/plain": [
       "90570 observations to process; with 1680 unique items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Most popular one\n",
    "popularity_model = turicreate.recommender.popularity_recommender.create(train_data, user_id='user_id',\n",
    "                                                                       item_id=\"movie_id\", target='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+------+\n",
      "| user_id | movie_id | score | rank |\n",
      "+---------+----------+-------+------+\n",
      "|    1    |   1500   |  5.0  |  1   |\n",
      "|    1    |   1201   |  5.0  |  2   |\n",
      "|    1    |   1189   |  5.0  |  3   |\n",
      "|    1    |   1122   |  5.0  |  4   |\n",
      "|    1    |   814    |  5.0  |  5   |\n",
      "|    2    |   1500   |  5.0  |  1   |\n",
      "|    2    |   1201   |  5.0  |  2   |\n",
      "|    2    |   1189   |  5.0  |  3   |\n",
      "|    2    |   1122   |  5.0  |  4   |\n",
      "|    2    |   814    |  5.0  |  5   |\n",
      "+---------+----------+-------+------+\n",
      "[25 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popularity_recomm = popularity_model.recommend(users=[1,2,3,4,5], k=5)\n",
    "# show top 5 recommendations.\n",
    "popularity_recomm.print_rows()\n",
    "# All users get the same recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Warning: Ignoring columns unix_timestamp;</pre>"
      ],
      "text/plain": [
       "Warning: Ignoring columns unix_timestamp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    To use these columns in scoring predictions, use a model that allows the use of additional features.</pre>"
      ],
      "text/plain": [
       "    To use these columns in scoring predictions, use a model that allows the use of additional features."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Preparing data set.</pre>"
      ],
      "text/plain": [
       "Preparing data set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data has 90570 observations with 943 users and 1680 items.</pre>"
      ],
      "text/plain": [
       "    Data has 90570 observations with 943 users and 1680 items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data prepared in: 0.048134s</pre>"
      ],
      "text/plain": [
       "    Data prepared in: 0.048134s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Training model from provided data.</pre>"
      ],
      "text/plain": [
       "Training model from provided data."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Gathering per-item and per-user statistics.</pre>"
      ],
      "text/plain": [
       "Gathering per-item and per-user statistics."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Elapsed Time (Item Statistics) | % Complete |</pre>"
      ],
      "text/plain": [
       "| Elapsed Time (Item Statistics) | % Complete |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1.334ms                        | 100        |</pre>"
      ],
      "text/plain": [
       "| 1.334ms                        | 100        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Setting up lookup tables.</pre>"
      ],
      "text/plain": [
       "Setting up lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Processing data in one pass using dense lookup tables.</pre>"
      ],
      "text/plain": [
       "Processing data in one pass using dense lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Elapsed Time (Constructing Lookups) | Total % Complete | Items Processed |</pre>"
      ],
      "text/plain": [
       "| Elapsed Time (Constructing Lookups) | Total % Complete | Items Processed |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4.306ms                             | 0.25             | 6               |</pre>"
      ],
      "text/plain": [
       "| 4.306ms                             | 0.25             | 6               |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 73.136ms                            | 100              | 1680            |</pre>"
      ],
      "text/plain": [
       "| 73.136ms                            | 100              | 1680            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finalizing lookup tables.</pre>"
      ],
      "text/plain": [
       "Finalizing lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Generating candidate set for working with new users.</pre>"
      ],
      "text/plain": [
       "Generating candidate set for working with new users."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished training in 0.078969s</pre>"
      ],
      "text/plain": [
       "Finished training in 0.078969s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# By item similarity\n",
    "item_sim_model = turicreate.item_similarity_recommender.create(train_data, user_id=\"user_id\", \n",
    "                                                              item_id='movie_id', target='rating',\n",
    "                                                              similarity_type='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+------+\n",
      "| user_id | movie_id |       score        | rank |\n",
      "+---------+----------+--------------------+------+\n",
      "|    1    |   423    | 0.980611449434557  |  1   |\n",
      "|    1    |   202    | 0.9542551061124293 |  2   |\n",
      "|    1    |   655    | 0.7947521701113869 |  3   |\n",
      "|    1    |   403    | 0.765623665037956  |  4   |\n",
      "|    1    |   568    | 0.7620385562190573 |  5   |\n",
      "|    2    |    50    | 1.1256258487701416 |  1   |\n",
      "|    2    |   181    | 1.0382135510444641 |  2   |\n",
      "|    2    |    7     | 0.9527609990193293 |  3   |\n",
      "|    2    |   121    | 0.9145556126649563 |  4   |\n",
      "|    2    |    9     | 0.8531226699168866 |  5   |\n",
      "+---------+----------+--------------------+------+\n",
      "[25 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_sim_recomm = item_sim_model.recommend(users=[1,2,3,4,5], k=5)\n",
    "item_sim_recomm.print_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different users get different recommendations based on each user's preference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By user similarity\n",
    "\n",
    "To compare movie ratings ny different users, we want ratings of all movies by every user.\n",
    "Of course, **not** every user has rated every movies. We will guess missing ratings of each user based on a set of other features of the user (called **latent features**.)\n",
    "To extract the most useful latent features from the existing features, we will use matric factorization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix factorization\n",
    "\n",
    "Matrix factorization is a general term. PCA is an example of matrix factorization. \n",
    "https://sites.google.com/site/igorcarron2/matrixfactorizations contains tons of information about matrix factorization. \n",
    "\n",
    "\n",
    "We decompose the complete rating matrix R as,  \n",
    "\n",
    "\\begin{equation*}\n",
    " R = P \\Sigma Q^{\\intercal}\n",
    "\\end{equation*}\n",
    "\n",
    "Here, R is the complete user $\\times$ movies rating matrix (M $\\times$ N),  \n",
    "P is M $\\times$ K user-feature affinity matrix which represents the association between users and (latent) features,  \n",
    "Q is N $\\times$ K latent feature - movie relevance matrix,  \n",
    "$\\Sigma$ is K$\\times$K feature weight matrix which represents the essential weights of features. (Not summation!)\n",
    "\n",
    "So, how do we determine R and Q?  \n",
    "In this example, we use **gradient descent** algorithm.\n",
    "\n",
    "We want to minimize the sum of the errors between the actual rating $r_{ui}$ and the predicted rating $\\check{r}_{ui}$ as\n",
    "\n",
    "\\begin{equation*}\n",
    "{e_{ui}}^2 = (r_{ui} - \\check{r}_{ui})^2 = (r_{ui} - \\sum _{k=1 }^{K }{ p_{uk} \\sigma_k q_{ki} })^2\n",
    "\\end{equation*}  \n",
    "\n",
    "\n",
    "In the gradient descent algorithm, p and q are updated so that the gradient of error is minimized. \n",
    "\n",
    "\\begin{align*}\n",
    "\\frac { \\partial  }{ \\partial { p }_{ uk } } ({ { e }_{ ui } }^{ 2 }) = -2({ r }_{ ui }-{ \\check { r }  }_{ ui }){ q }_{ ki }=-2{ e }_{ ui }{ q }_{ ki } \\\\\n",
    "\\frac { \\partial  }{ \\partial { q }_{ ki } } ({ { e }_{ ui } }^{ 2 }) = -2({ r }_{ ui }-{ \\check { r }  }_{ ui }){ p }_{ uk }=-2{ e }_{ ui }{ p }_{ uk }\n",
    "\\end{align*}\n",
    "\n",
    "Now, let the system evolve according to the *update rule*, or PDEs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "    \"\"\"\n",
    "    R = rating matrix\n",
    "    K = Numbre of latent features\n",
    "    alpha = Learning rate (delta one step = alpha * gradient)\n",
    "    beta = Regularization parameter for bias\n",
    "    \n",
    "    P = prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        \n",
    "    # Initialize\n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "        \n",
    "        # Initializing the bias terms ???\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        #self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "        self.b = np.mean(self.R[self.R != 0])\n",
    "        \n",
    "        self.samples = [\n",
    "            (i,j, self.R[i,j]) \n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i,j] >0\n",
    "        ]\n",
    "        \n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i,mse))\n",
    "            if i+1 % 20 == 0:\n",
    "                print(\"Iteration: %d ; error = %.4f\".format(i+1, mse))\n",
    "                \n",
    "        return training_process\n",
    "    \n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        Mean squared error\n",
    "        \"\"\"\n",
    "        i_missing = self.R.nonzero() # Return the indices of the elements that are non-zero.\n",
    "        predicted = self.full_matrix()\n",
    "        return np.sqrt(np.sum(np.square(self.R[i_missing] - predicted[i_missing])))\n",
    "    \n",
    "    \n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "            stochastic gradient descent \n",
    "        \"\"\"\n",
    "        for i,j,r in self.samples:\n",
    "            prediction = self.get_rating(i,j)\n",
    "            e = r - prediction\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.alpha * self.b_i[j])\n",
    "            self.P[i,:] += self.alpha * (e * self.Q[j,:] - self.beta * self.P[i,:])\n",
    "            self.Q[j,:] += self.alpha * (e * self.P[i,:] - self.beta * self.Q[j,:])\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        return self.b + self.b_u[i] + self.b_i[j] + \\\n",
    "               np.dot(self.P[i,:], self.Q[j,:].T)\n",
    "    \n",
    "    def full_matrix(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + \\\n",
    "               self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "# convert user ratings to matrix form.\n",
    "# pd.pivot\n",
    "#   Return reshaped DataFrame organized by given index / column values.\n",
    "R = np.array(ratings.pivot(index = 'user_id', \n",
    "                           columns = 'movie_id', \n",
    "                           values ='rating').fillna(0))\n",
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MF(R, K=20, alpha=0.001, beta=0.01, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 337.59117477665035),\n",
       " (1, 327.02008959794387),\n",
       " (2, 320.24510881421156),\n",
       " (3, 315.54492665646654),\n",
       " (4, 312.08358682395675),\n",
       " (5, 309.42212419737),\n",
       " (6, 307.3030738108998),\n",
       " (7, 305.5683580542252),\n",
       " (8, 304.1174025784298),\n",
       " (9, 302.88265944451115),\n",
       " (10, 301.8134740002398),\n",
       " (11, 300.87640113094875),\n",
       " (12, 300.046107018827),\n",
       " (13, 299.3038402990994),\n",
       " (14, 298.6349423254205),\n",
       " (15, 298.02785798359264),\n",
       " (16, 297.4740190745409),\n",
       " (17, 296.96603926810565),\n",
       " (18, 296.4983368970952),\n",
       " (19, 296.06504845826515),\n",
       " (20, 295.6623642321388),\n",
       " (21, 295.28725924804337),\n",
       " (22, 294.9355023340405),\n",
       " (23, 294.6055551163985),\n",
       " (24, 294.29514775581606),\n",
       " (25, 294.0014235816799),\n",
       " (26, 293.72355944036326),\n",
       " (27, 293.4596487152364),\n",
       " (28, 293.2086844883392),\n",
       " (29, 292.9689578424467),\n",
       " (30, 292.73937760933774),\n",
       " (31, 292.51898357860375),\n",
       " (32, 292.3075311762075),\n",
       " (33, 292.10380164233356),\n",
       " (34, 291.9062459331664),\n",
       " (35, 291.71488430253834),\n",
       " (36, 291.52967813881537),\n",
       " (37, 291.3488578410917),\n",
       " (38, 291.17220958469903),\n",
       " (39, 290.9994326828665),\n",
       " (40, 290.8305254767431),\n",
       " (41, 290.6631648642534),\n",
       " (42, 290.498471681058),\n",
       " (43, 290.3356290677799),\n",
       " (44, 290.1739054578048),\n",
       " (45, 290.0138874289671),\n",
       " (46, 289.85481176569994),\n",
       " (47, 289.69496135053276),\n",
       " (48, 289.53484720032736),\n",
       " (49, 289.3741904957189),\n",
       " (50, 289.2131501911903),\n",
       " (51, 289.0511845091055),\n",
       " (52, 288.8866367557419),\n",
       " (53, 288.720279992041),\n",
       " (54, 288.5518687675475),\n",
       " (55, 288.3807640394789),\n",
       " (56, 288.2064039623108),\n",
       " (57, 288.02798077101835),\n",
       " (58, 287.84655270675387),\n",
       " (59, 287.66077580759134),\n",
       " (60, 287.4697404849185),\n",
       " (61, 287.27403788950636),\n",
       " (62, 287.07282152833994),\n",
       " (63, 286.8657708605214),\n",
       " (64, 286.6524343009459),\n",
       " (65, 286.4323306313915),\n",
       " (66, 286.20597921705604),\n",
       " (67, 285.9719935053374),\n",
       " (68, 285.7296991547008),\n",
       " (69, 285.47864107673104),\n",
       " (70, 285.22037590871395),\n",
       " (71, 284.95303741499424),\n",
       " (72, 284.6761466085821),\n",
       " (73, 284.389388138357),\n",
       " (74, 284.0933441602136),\n",
       " (75, 283.78681888681024),\n",
       " (76, 283.4697432097318),\n",
       " (77, 283.1422634316103),\n",
       " (78, 282.8041918266159),\n",
       " (79, 282.4549255915576),\n",
       " (80, 282.0944071281412),\n",
       " (81, 281.72277614473086),\n",
       " (82, 281.34001984043135),\n",
       " (83, 280.9460524101512),\n",
       " (84, 280.5409603858663),\n",
       " (85, 280.1245050582868),\n",
       " (86, 279.69696136592137),\n",
       " (87, 279.2588505790225),\n",
       " (88, 278.810083007206),\n",
       " (89, 278.3511892979243),\n",
       " (90, 277.88293322090465),\n",
       " (91, 277.4051418844065),\n",
       " (92, 276.91712354438795),\n",
       " (93, 276.42171408368694),\n",
       " (94, 275.91682585321064),\n",
       " (95, 275.40373732336417),\n",
       " (96, 274.8835615984533),\n",
       " (97, 274.3568878198145),\n",
       " (98, 273.8221920769309),\n",
       " (99, 273.2821298844354)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictied ratings\n",
      "[4.00607722 3.3241638  3.09252022 ... 2.88405447 2.45350727 3.18294452]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictied ratings\")\n",
    "print(mf.full_matrix()[mf.R.nonzero()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do, \n",
    "\n",
    "What is the bias??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### metrics used\n",
    "\n",
    "1. Recall\n",
    "\\begin{equation*}\n",
    " R =\\frac{good\\, prediction}{good\\, prediction + good\\, given}\n",
    "\\end{equation*}\n",
    "\n",
    "Better prediction with smaller data means higher recall.\n",
    "But, if the engine recommended everything, the Recall is high.\n",
    "\n",
    "2. Prediction\n",
    "\\begin{equation*}\n",
    " P =\\frac{good\\, prediction}{total\\, prediction}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "So, recall ~ coverage, prediction ~ success rate.\n",
    "\n",
    "3. RMS error\n",
    "\\begin{equation*}\n",
    "RMSE=\\sqrt { \\frac { \\sum _{ i=1 }^{ N }{ (predicted_{ i }-Actual_{ i }) }  }{ N }  } \n",
    "\\end{equation*}\n",
    "\n",
    "#### ranking metrics (more weights on more favored recommendation)\n",
    "4. Mean Reciprocal Rank\n",
    "\\begin{equation*}\n",
    "MRR=\\frac { 1 }{ N } \\sum _{ i=1 }^{ N }{ \\frac { 1 }{ r({ Q }_{ i }) }  }\n",
    "\\end{equation*}\n",
    ", where r is the rank, Q maybe a *non-ranked* metric such as R or P.\n",
    "\n",
    "\n",
    "5. MAP at K (Mean Average Precision at cutoff K)\n",
    "\\begin{equation*}\n",
    "{ MAP }_{ i }=\\frac { 1 }{ \\left| { R }_{ i } \\right|  } \\sum _{ k=1 }^{ R_{ i } }{ P({ R }_{ i }\\left[ k \\right] ) } \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
